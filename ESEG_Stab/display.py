import os
import numpy as np
import matplotlib
matplotlib.use('Agg')
matplotlib.rcParams['pdf.fonttype'] = 42  
matplotlib.rcParams['ps.fonttype']  = 42
SAVE_PDF = False  
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
import torch
from datetime import datetime
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, r2_score
from scipy.stats import pearsonr
from matplotlib.ticker import MaxNLocator
from sklearn.metrics import roc_curve, auc, precision_recall_curve


# ============== å…¨å±€é£æ ¼ ==============
sns.set_theme(
    context="notebook",
    style="whitegrid",
    rc={
        "axes.spines.right": False,
        "axes.spines.top": False,
        "axes.linewidth": 1.1,
        "grid.linewidth": 0.6,
        "grid.linestyle": "--",
        "figure.dpi": 300,
        "savefig.dpi": 300,
        "font.size": 12,
        "axes.titlesize": 13,
        "axes.labelsize": 13,
        "legend.fontsize": 11,
        "xtick.labelsize": 11,
        "ytick.labelsize": 11,
    },
)


# ============== å°å·¥å…· ==============
def _ensure_dir(d):
    os.makedirs(d, exist_ok=True)


def _save(fig, path_wo_ext: str):
    try:
        fig.tight_layout()
    except Exception:
        pass

    png_path = path_wo_ext + ".png"
    fig.savefig(png_path, bbox_inches="tight")
    print(f"âœ… PNG saved: {png_path}", flush=True)

    if SAVE_PDF:
        pdf_path = path_wo_ext + ".pdf"
        try:
            print(f"ğŸ“ saving PDF -> {pdf_path}", flush=True)
            fig.savefig(pdf_path, bbox_inches="tight")
            print(f"âœ… PDF saved: {pdf_path}", flush=True)
        except Exception as e:
            print(f"âš ï¸ PDF save skipped: {e}", flush=True)

    plt.close(fig)


def _metrics(preds, targets):
    preds   = np.asarray(preds, dtype=float).reshape(-1)
    targets = np.asarray(targets, dtype=float).reshape(-1)
    m = np.isfinite(preds) & np.isfinite(targets)
    preds, targets = preds[m], targets[m]
    rmse = float(np.sqrt(np.mean((preds - targets) ** 2)))
    mae  = float(mean_absolute_error(targets, preds))
    r2   = float(r2_score(targets, preds))
    pr   = float(pearsonr(targets, preds)[0]) if preds.std() > 0 and targets.std() > 0 else 0.0
    return rmse, mae, r2, pr


def _ema(x, beta=0.9):
    if x is None or len(x) == 0:
        return x
    y = []
    m = None
    for v in x:
        m = v if m is None else beta * m + (1 - beta) * v
        y.append(m)
    return y


# ============== ROCå’ŒPRæ›²çº¿ ==============
def visualize_roc_pr_curves(preds, targets, save_dir, threshold=1.0):
    """
    ç”ŸæˆROCæ›²çº¿å’ŒPRæ›²çº¿
    """
    _ensure_dir(save_dir)
    
    binary_targets = (np.abs(targets) >= threshold).astype(int)
    pred_scores = np.abs(preds)  
    
    # ====== ROCæ›²çº¿ ======
    fpr, tpr, _ = roc_curve(binary_targets, pred_scores)
    roc_auc = auc(fpr, tpr)
    
    fig, ax = plt.subplots(figsize=(6.0, 5.0))
    ax.plot(fpr, tpr, color='#0072B2', lw=2.5, label=f'ROC curve (AUC = {roc_auc:.3f})')
    ax.plot([0, 1], [0, 1], color='#555555', lw=1.5, linestyle='--', alpha=0.8)
    ax.set_xlim([0.0, 1.0])
    ax.set_ylim([0.0, 1.05])
    ax.set_xlabel('False Positive Rate')
    ax.set_ylabel('True Positive Rate')
    ax.set_title('ROC Curve')
    ax.legend(loc="lower right", frameon=True, framealpha=0.9)
    ax.grid(alpha=0.3, linestyle="--", linewidth=0.6)
    
    _save(fig, os.path.join(save_dir, "roc_curve"))
    plt.close(fig)
    
    # ====== PRæ›²çº¿ ======
    precision, recall, _ = precision_recall_curve(binary_targets, pred_scores)
    pr_auc = auc(recall, precision)
    
    fig, ax = plt.subplots(figsize=(6.0, 5.0))
    ax.plot(recall, precision, color='#D55E00', lw=2.5, label=f'PR curve (AUC = {pr_auc:.3f})')
    ax.set_xlim([0.0, 1.0])
    ax.set_ylim([0.0, 1.05])
    ax.set_xlabel('Recall')
    ax.set_ylabel('Precision')
    ax.set_title('Precision-Recall Curve')
    ax.legend(loc="upper right", frameon=True, framealpha=0.9)
    ax.grid(alpha=0.3, linestyle="--", linewidth=0.6)
    
    _save(fig, os.path.join(save_dir, "pr_curve"))
    plt.close(fig)


# ============== è¯¯å·®çƒ­åŠ›å›¾ ==============
def visualize_error_heatmap(preds, targets, save_dir, bins=30):
    """
    ç”Ÿæˆè¯¯å·®çƒ­åŠ›å›¾
    """
    _ensure_dir(save_dir)
    
    residuals = preds - targets
    
    fig, ax = plt.subforms(figsize=(7.0, 5.5))

    hb = ax.hexbin(targets, residuals, gridsize=bins, cmap='viridis', alpha=0.8)
    cb = fig.colorbar(hb, ax=ax)
    cb.set_label('Count')
    
    ax.axhline(y=0, color='#E24A33', linestyle='--', linewidth=1.5, label='Zero error')

    z = np.polyfit(targets, residuals, 1)
    p = np.poly1d(z)
    ax.plot(targets, p(targets), color='#0072B2', linewidth=2.0, label='Trend line')
    
    ax.set_xlabel('Experimental Î”Î”G (kcal/mol)')
    ax.set_ylabel('Residual (Pred âˆ’ Exp)')
    ax.set_title('Error Heatmap')
    ax.legend(loc="best", frameon=True, framealpha=0.9)
    ax.grid(alpha=0.3, linestyle="--", linewidth=0.6)
    
    _save(fig, os.path.join(save_dir, "error_heatmap"))
    plt.close(fig)


# ============== å…¶ä»–åŠŸèƒ½å‡½æ•°=============
def visualize_training_only(history, val_results, output_dir, config=None):
    """ç»Ÿä¸€é£æ ¼åçš„è®­ç»ƒå¯è§†åŒ–"""
    _ensure_dir(output_dir)
    
    # ä½¿ç”¨ç»Ÿä¸€çš„è®­ç»ƒæ›²çº¿å¯è§†åŒ–
    visualize_training_curves(history, output_dir)
    
    # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    report = f"""Model Performance Report
========================
Generated on: {timestamp}

[Basic Metrics]
- RMSE: {val_results['rmse']:.3f}
- MAE: {val_results.get('mae', 'NA'):.3f}
- RÂ²: {val_results.get('r2', 'NA'):.3f}
- Pearson: {val_results.get('pearson', 'NA'):.3f}

[Training Info]
- Total Epochs: {len(history['train_loss'])}
- Best Validation Epoch: {np.argmin(history['val_rmse']) + 1 if 'val_rmse' in history else 'NA'}
"""

    if config is not None:
        report += "\n[Model Hyperparameters]\n"
        for k, v in vars(config).items():
            if k.startswith('__') or callable(v):
                continue
            report += f"- {k}: {v}\n"

    with open(os.path.join(output_dir, 'performance_report.txt'), 'w') as f:
        f.write(report)

    print(f"ğŸ“Š è®­ç»ƒé˜¶æ®µå¯è§†åŒ–ç»“æœå›¾å’Œç»¼åˆæŠ¥å‘Šå·²ç”Ÿæˆå¹¶ä¿å­˜åˆ°ç›®å½•: {output_dir}")


def visualize_train_or_test_results(val_results, output_dir):
    """ç»Ÿä¸€é£æ ¼åçš„éªŒè¯/æµ‹è¯•ç»“æœå¯è§†åŒ–"""
    _ensure_dir(output_dir)
    
    if 'preds' in val_results and 'targets' in val_results:
        # ä½¿ç”¨ç»Ÿä¸€çš„é¢„æµ‹å¯è§†åŒ–
        visualize_prediction_scatter(val_results['preds'], val_results['targets'], output_dir)
        
        # æ·»åŠ ROCå’ŒPRæ›²çº¿
        visualize_roc_pr_curves(val_results['preds'], val_results['targets'], output_dir)
        
        # æ·»åŠ è¯¯å·®çƒ­åŠ›å›¾
        visualize_error_heatmap(val_results['preds'], val_results['targets'], output_dir)
        
        print(f"âœ… éªŒè¯oræµ‹è¯•é˜¶æ®µåˆ†æå›¾å·²ç”Ÿæˆå¹¶ä¿å­˜åˆ°ç›®å½•: {output_dir}")


# ============== è®­ç»ƒæ›²çº¿ ==============
def visualize_training_curves(history, save_dir, learning_rates=None, smooth=0.9):
    """
    ç”Ÿæˆï¼š
      1) å•å›¾ç‰ˆ:loss_rmse_curve / val_mae_curve / val_pearson_r2
      2) çœ‹æ¿ç‰ˆ:training_dashboard(å››å®«æ ¼å« LR)
    """
    _ensure_dir(save_dir)
    # CSV
    epochs = list(range(1, len(history["train_loss"]) + 1))
    df = pd.DataFrame({
        "epoch": epochs,
        "train_loss": history["train_loss"],
        "val_rmse": history["val_rmse"],
        "val_mae": history["val_mae"],
        "val_r2": history["val_r2"],
        "val_pearson": history["val_pearson"],
    })

    # æ§åˆ¶å°æ•°ä½
    decimals = {
        "train_loss": 4, "val_rmse": 3, "val_mae": 3, "val_r2": 3, "val_pearson": 3,
        "lr_enc": 6, "lr_out": 6,
    }
    df = df.round({k: v for k, v in decimals.items() if k in df.columns})

    if learning_rates is not None:
        # å…è®¸ (enc_lr, out_lr) çš„äºŒå…ƒç»„
        if isinstance(learning_rates[0], (list, tuple)):
            df["lr_enc"] = [lr[0] for lr in learning_rates][:len(df)]
            df["lr_out"] = [lr[1] for lr in learning_rates][:len(df)]
        else:
            df["lr_enc"] = learning_rates[:len(df)]

    csv_path = os.path.join(save_dir, "train_log.csv")
    df.to_csv(csv_path, index=False)
    print(f"âœ… ä¿å­˜è®­ç»ƒæ—¥å¿—è‡³: {csv_path}")

    # å¯é€‰ EMA
    train_loss = _ema(history["train_loss"], smooth) if smooth else history["train_loss"]
    val_rmse   = _ema(history["val_rmse"], smooth)   if smooth else history["val_rmse"]
    val_mae    = _ema(history["val_mae"], smooth)    if smooth else history["val_mae"]
    val_r2     = _ema(history["val_r2"], smooth)     if smooth else history["val_r2"]
    val_p      = _ema(history["val_pearson"], smooth)if smooth else history["val_pearson"]

    # ---- å•å›¾ï¼šLoss + RMSE ----
    fig, ax = plt.subplots(figsize=(5.4, 4.2))
    ax.plot(train_loss, label="Train Loss", linewidth=1.8)
    ax.set_xlabel("Epoch"); ax.set_ylabel("Train Loss")
    ax2 = ax.twinx()
    ax2.plot(val_rmse, label="Val RMSE", color="#D55E00", linewidth=1.8)
    ax2.set_ylabel("Val RMSE (kcal/mol)")
    ax.grid(True, linestyle="--", linewidth=0.6)
    ax.set_title("Training Loss & Validation RMSE")
    # åˆå¹¶å›¾ä¾‹
    lines, labels = ax.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax.legend(lines + lines2, labels + labels2, frameon=False, loc="best")
    _save(fig, os.path.join(save_dir, "loss_rmse_curve"))
    plt.close(fig)

    # ---- å•å›¾ï¼šMAE ----
    fig, ax = plt.subplots(figsize=(5.4, 4.2))
    ax.plot(val_mae, color="#009E73", linewidth=1.8)
    ax.set_xlabel("Epoch"); ax.set_ylabel("MAE (kcal/mol)")
    ax.set_title("Validation MAE")
    ax.grid(True, linestyle="--", linewidth=0.6)
    _save(fig, os.path.join(save_dir, "val_mae_curve"))
    plt.close(fig)

    # ---- å•å›¾ï¼šPearson & RÂ² ----
    fig, ax = plt.subplots(figsize=(5.4, 4.2))
    ax.plot(val_p, label="Pearson", color="#0072B2", linewidth=1.8)
    ax.plot(val_r2, label="RÂ²", color="#CC79A7", linewidth=1.8)
    ax.set_xlabel("Epoch"); ax.set_ylabel("Score")
    ax.set_title("Validation Pearson & RÂ²")
    ax.grid(True, linestyle="--", linewidth=0.6)
    ax.legend(frameon=False, loc="best")
    _save(fig, os.path.join(save_dir, "val_pearson_r2"))
    plt.close(fig)

    # ---- å››å®«æ ¼çœ‹æ¿ ----
    fig, axes = plt.subplots(2, 2, figsize=(10.5, 7.8))
    ax = axes[0, 0]
    ax.plot(train_loss, label="Train Loss", linewidth=1.8)
    ax2 = ax.twinx()
    ax2.plot(val_rmse, label="Val RMSE", color="#D55E00", linewidth=1.8)
    ax.set_title("Loss & RMSE"); ax.set_xlabel("Epoch"); ax.set_ylabel("Loss")
    ax2.set_ylabel("RMSE")
    ax.grid(True, linestyle="--", linewidth=0.6)
    # å›¾ä¾‹
    lines, labels = ax.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax.legend(lines + lines2, labels + labels2, frameon=False, loc="best")

    ax = axes[0, 1]
    ax.plot(val_mae, color="#009E73", linewidth=1.8)
    ax.set_title("MAE"); ax.set_xlabel("Epoch"); ax.set_ylabel("MAE (kcal/mol)")
    ax.grid(True, linestyle="--", linewidth=0.6)

    ax = axes[1, 0]
    ax.plot(val_p, label="Pearson", color="#0072B2", linewidth=1.8)
    ax.plot(val_r2, label="RÂ²", color="#CC79A7", linewidth=1.8)
    ax.set_title("Pearson & RÂ²"); ax.set_xlabel("Epoch"); ax.set_ylabel("Score")
    ax.grid(True, linestyle="--", linewidth=0.6)
    ax.legend(frameon=False, loc="best")

    ax = axes[1, 1]
    if learning_rates is not None:
        if isinstance(learning_rates[0], (list, tuple)):
            lr_enc = [lr[0] for lr in learning_rates][:len(train_loss)]
            lr_out = [lr[1] for lr in learning_rates][:len(train_loss)]
            ax.plot(lr_enc, label="LR (Encoder)", linewidth=1.6)
            ax.plot(lr_out, label="LR (Readout)", linewidth=1.6)
        else:
            ax.plot(learning_rates[:len(train_loss)], label="Learning Rate", linewidth=1.6)
        ax.set_yscale("log")
        ax.legend(frameon=False, loc="best")
    ax.set_title("Learning Rate"); ax.set_xlabel("Epoch"); ax.set_ylabel("LR (log)")
    ax.grid(True, linestyle="--", linewidth=0.6)
    for a in axes.flat:
        a.xaxis.set_major_locator(MaxNLocator(integer=True))

    _save(fig, os.path.join(save_dir, "training_dashboard"))
    plt.close(fig)


# ============== é¢„æµ‹æ•£ç‚¹ + è¾¹ç¼˜åˆ†å¸ƒ + æ®‹å·® + è¯¯å·®åˆ†å¸ƒ ==============
def visualize_prediction_scatter(preds, targets, save_dir, title="Prediction vs. Ground Truth"):
    """
    ç”Ÿæˆä¸‰å¼ å›¾ï¼š
      1) scatter_ddg.png         â€” å›å½’æ•£ç‚¹
      2) residual_plot.png       â€” æ®‹å·®å›¾
      3) error_distribution.png  â€” è¯¯å·®åˆ†å¸ƒ
    """
    _ensure_dir(save_dir)

    preds = np.asarray(preds, dtype=float).reshape(-1)
    targets = np.asarray(targets, dtype=float).reshape(-1)
    m = np.isfinite(preds) & np.isfinite(targets)
    preds, targets = preds[m], targets[m]
    rmse, mae, r2, pr = _metrics(preds, targets)
    n = preds.size

    # ====== (A) è”åˆæ•£ç‚¹ï¼ˆä¸­å¿ƒæ•£ç‚¹ + ç­‰å€¼çº¿å¯†åº¦ + è¾¹ç¼˜ç›´æ–¹å›¾ï¼‰======
    df = pd.DataFrame({"True": targets, "Pred": preds}).apply(pd.to_numeric, errors="coerce").dropna()
    targets = df["True"].to_numpy(dtype=float, copy=False)
    preds   = df["Pred"].to_numpy(dtype=float, copy=False)

    low  = float(np.min([targets.min(), preds.min()]))
    high = float(np.max([targets.max(), preds.max()]))
    pad  = 0.05 * (high - low if high > low else 1.0)
    xlim = ylim = (low - pad, high + pad)

    point_c = "#4C78A8"   # è“
    ident_c = "#DD8452"   # æ©™ï¼ˆå¯¹è§’çº¿ï¼‰
    fit_c   = "#55A868"   # ç»¿ï¼ˆæ‹Ÿåˆï¼‰

    reg = LinearRegression().fit(targets.reshape(-1, 1), preds)

    fig, ax = plt.subplots(figsize=(6.0, 4.8))
    ax.scatter(targets, preds, s=24, alpha=0.78, linewidth=0, color=point_c, zorder=2)
    ax.plot(xlim, xlim, ls="--", color=ident_c, lw=2.1, label="Identity (y=x)", zorder=1)

    xs = np.array(xlim).reshape(-1, 1)
    ax.plot(xs, reg.predict(xs), color=fit_c, lw=2.1, label="Linear fit", zorder=3)

    ax.set_xlim(xlim); ax.set_ylim(ylim)
    ax.set_aspect("equal", adjustable="box")
    ax.set_xlabel("Experimental Î”Î”G (kcal/mol)")
    ax.set_ylabel("Predicted Î”Î”G (kcal/mol)")
    if title: ax.set_title("Prediction vs. Experimental")

    for side in ("top", "right"):   ax.spines[side].set_visible(False)
    for side in ("left", "bottom"): ax.spines[side].set_color("#666"); ax.spines[side].set_linewidth(0.9)

    txt = f"RMSE={rmse:.3f}\nMAE={mae:.3f}\nPCC={pr:.3f}"
    ax.text(0.02, 0.98, txt, transform=ax.transAxes,
            va="top", ha="left", fontsize=10, family="monospace",
            bbox=dict(boxstyle="round,pad=0.30", fc="white", ec="0.6", lw=0.8, alpha=0.95))
    ax.legend(loc="lower right", frameon=True, framealpha=0.9)
    ax.grid(alpha=0.3, linestyle="--", linewidth=0.6)

    _save(fig, os.path.join(save_dir, "scatter_ddg"))
    plt.close(fig)

    # ====== (B) æ®‹å·®å›¾ï¼ˆåˆ†ç®±å‡å€¼ + ç½®ä¿¡å¸¦ï¼‰======
    residuals = preds - targets
    fig, ax = plt.subplots(figsize=(5.8, 4.6))
    ax.scatter(targets, residuals, s=20, alpha=0.65, linewidth=0, color=point_c)
    ax.axhline(0, color="grey", ls="--", lw=1.2, label="Zero error")

    bins = np.linspace(targets.min(), targets.max(), 21)
    idx = np.digitize(targets, bins) - 1
    bin_x, bin_mu, bin_lo, bin_hi = [], [], [], []
    for b in range(len(bins)-1):
        msk = (idx == b)
        if msk.any():
            vals = residuals[msk]
            bin_x.append(0.5 * (bins[b] + bins[b+1]))
            mu  = vals.mean()
            sd  = vals.std(ddof=1) if vals.size > 1 else 0.0
            bin_mu.append(mu)
            bin_lo.append(mu - 1.96 * sd / max(1, np.sqrt(vals.size)))
            bin_hi.append(mu + 1.96 * sd / max(1, np.sqrt(vals.size)))
    if bin_x:
        ax.plot(bin_x, bin_mu, color=fit_c, lw=2.0, label="Binned mean")
        ax.fill_between(bin_x, bin_lo, bin_hi, color=fit_c, alpha=0.15, label="â‰ˆ95% CI")

    ax.set_xlabel("Experimental Î”Î”G (kcal/mol)")
    ax.set_ylabel("Residual (Pred âˆ’ Exp)")
    ax.set_title("Residuals vs. Experimental Î”Î”G")
    ax.legend(loc="best", frameon=True, framealpha=0.9)
    ax.grid(alpha=0.3, linestyle="--", linewidth=0.6)
    _save(fig, os.path.join(save_dir, "residual_plot"))
    plt.close(fig)

    # ====== (C) è¯¯å·®åˆ†å¸ƒ ======
    fig, ax = plt.subplots(figsize=(6.2, 4.6))
    bar_c    = "#1F77B4"   # äº®è“æŸ±
    kde_c    = "#124E8C"   # æ·±è“ KDE
    median_c = "#E24A33"   # çº¢è‰²è™šçº¿ï¼ˆä¸­ä½æ•°ï¼‰

    sns.histplot(residuals, bins=30, kde=False, color=bar_c,
                edgecolor="white", linewidth=0.5, alpha=0.85, ax=ax)
    sns.kdeplot(residuals, color=kde_c, lw=2.0, ax=ax)

    mu  = residuals.mean(); med = np.median(residuals); sd = residuals.std(ddof=1)

    ax.axvline(med,     color=median_c, lw=2.2, ls="--", label=f"Median={med:.3f}")
    ax.axvline(mu,      color="#555",   lw=1.2, ls="-",  alpha=0.75, label=f"Mean={mu:.3f}")
    ax.axvline(mu - sd, color="0.65",   lw=1.0, ls=":",  alpha=0.8,  label=f"Â±1Ïƒ={sd:.3f}")
    ax.axvline(mu + sd, color="0.65",   lw=1.0, ls=":",  alpha=0.8)

    ax.set_xlabel("Prediction Error (kcal/mol)")
    ax.set_ylabel("Count")
    ax.set_title("Error Distribution")
    ax.legend(loc="best", frameon=True, framealpha=0.9)
    ax.grid(alpha=0.3, linestyle="--", linewidth=0.6)

    _save(fig, os.path.join(save_dir, "error_distribution"))
    plt.close(fig)

    # ====== (D) å››åˆä¸€æŠ¥å‘Šï¼ˆæ•£ç‚¹ + æ®‹å·® + è¯¯å·® + æŒ‡æ ‡æ¡†ï¼‰======
    fig = plt.figure(figsize=(10.5, 8.2), constrained_layout=True)
    gs = fig.add_gridspec(2, 2, wspace=0.32, hspace=0.28)

    # 1. æ•£ç‚¹
    ax = fig.add_subplot(gs[0, 0])
    ax.scatter(targets, preds, s=22, alpha=0.78, linewidth=0, color=point_c)
    ax.plot(xlim, xlim, ls="--", color=ident_c, lw=2.1, label="Identity (y=x)")
    xs = np.array(xlim).reshape(-1, 1)
    ax.plot(xs, reg.predict(xs), color=fit_c, lw=2.1, label="Linear fit")
    ax.set_xlim(xlim); ax.set_ylim(ylim); ax.set_aspect("equal", adjustable="box")
    ax.set_xlabel("Experimental Î”Î”G (kcal/mol)")
    ax.set_ylabel("Predicted Î”Î”G (kcal/mol)")
    ax.set_title("Prediction vs. Experimental")
    box = f"RMSE={rmse:.3f}\nMAE={mae:.3f}\nPCC={pr:.3f}"
    ax.text(0.02, 0.98, box, transform=ax.transAxes,
            va="top", ha="left", fontsize=10, family="monospace",
            bbox=dict(boxstyle="round,pad=0.30", fc="white", ec="0.6", lw=0.8, alpha=0.95))
    ax.legend(loc="lower right", frameon=True, framealpha=0.9)
    ax.grid(alpha=0.3, linestyle="--", linewidth=0.6)

    # 2. æ®‹å·®
    ax2 = fig.add_subplot(gs[0, 1])
    ax2.scatter(targets, residuals, s=20, alpha=0.65, linewidth=0, color=point_c)
    ax2.axhline(0, color="grey", ls="--", lw=1.2, label="Zero error")
    if bin_x:
        ax2.plot(bin_x, bin_mu, color=fit_c, lw=2.0, label="Binned mean")
        ax2.fill_between(bin_x, bin_lo, bin_hi, color=fit_c, alpha=0.15, label="â‰ˆ95% CI")
    ax2.set_xlabel("Experimental Î”Î”G (kcal/mol)")
    ax2.set_ylabel("Residual (Pred âˆ’ Exp)")
    ax2.set_title("Residuals")
    ax2.legend(loc="best", frameon=True, framealpha=0.9)
    ax2.grid(alpha=0.3, linestyle="--", linewidth=0.6)

    # 3. è¯¯å·®åˆ†å¸ƒ
    ax3 = fig.add_subplot(gs[1, 0])
    sns.histplot(residuals, bins=30, kde=True, color=bar_c, edgecolor=None, ax=ax3)
    ax3.axvline(mu,  color=point_c, lw=1.8, label=f"Mean={mu:.3f}")
    ax3.axvline(med, color=fit_c,   lw=1.8, ls="--", label=f"Median={med:.3f}")
    ax3.axvline(mu - sd, color="0.5", lw=1.1, ls=":", label=f"Â±1Ïƒ={sd:.3f}")
    ax3.axvline(mu + sd, color="0.5", lw=1.1, ls=":")
    ax3.set_xlabel("Prediction Error (kcal/mol)")
    ax3.set_ylabel("Count")
    ax3.set_title("Error Distribution")
    ax3.legend(loc="best", frameon=True, framealpha=0.9)
    ax3.grid(alpha=0.3, linestyle="--", linewidth=0.6)

    # 4. æŒ‡æ ‡ä¿¡æ¯æ¡†ï¼ˆæ•´é¡µï¼‰
    ax4 = fig.add_subplot(gs[1, 1]); ax4.axis("off")
    stats_text = (
        f"N = {n}\n\n"
        f"RMSE = {rmse:.3f}\n"
        f"MAE = {mae:.3f}\n"
        f"RÂ² = {r2:.3f}\n"
        f"Pearson = {pr:.3f}\n"
        f"\n"
        f"Mean(True) = {targets.mean():.3f}\n"
        f"Std(True)  = {targets.std(ddof=1):.3f}\n"
        f"Mean(Pred) = {preds.mean():.3f}\n"
        f"Std(Pred)  = {preds.std(ddof=1):.3f}"
    )
    ax4.text(0.02, 0.98, stats_text, va="top", ha="left",
             fontsize=13, family="monospace",
             bbox=dict(boxstyle="round,pad=0.5", fc="white", ec="#999999", lw=1.0, alpha=0.95))

    _save(fig, os.path.join(save_dir, "prediction_report"))
    plt.close(fig)


# ============== åµŒå…¥å¯è§†åŒ– ==============
def visualize_embeddings(features=None, labels=None, save_dir=".", filename="embeddings.png", method="pca", **kwargs):
    full_loader = kwargs.get("full_loader", None)
    model = kwargs.get("model", None)
    device = kwargs.get("device", None)
    cls_threshold = float(kwargs.get("cls_threshold", 1.0))

    if features is None and full_loader is not None:
        feats_list, labs_list = [], []
        use_amp = (device is not None and isinstance(device, torch.device) and device.type == "cuda")
        amp_dtype = torch.bfloat16 if (use_amp and torch.cuda.is_bf16_supported()) else torch.float16

        if model is not None and device is not None:
            model_was_train = model.training
            model.eval()

        with torch.cuda.amp.autocast(enabled=use_amp, dtype=amp_dtype):
            for batch in full_loader:
                ddg = batch.get("ddG", None)
                if ddg is not None:
                    y = ddg.detach().cpu().numpy() if torch.is_tensor(ddg) else np.asarray(ddg)
                    lab = (np.abs(y) >= cls_threshold).astype(int).reshape(-1)
                else:
                    lab = np.zeros((1,), dtype=int)

                if "features" in batch:
                    x = batch["features"]
                    x = x.detach().cpu().numpy() if torch.is_tensor(x) else np.asarray(x)
                    x = x.reshape(x.shape[0], -1) if x.ndim > 1 else x.reshape(1, -1)
                else:
                    x_vec = None
                    if model is not None and device is not None:
                        try:
                            wild_ids = batch["wild_ids"].to(device)
                            mut_ids  = batch["mut_ids"].to(device)
                            pos      = batch["positions"].to(device)
                            feats_in = batch["features"].to(device) if "features" in batch else None
                            with torch.no_grad():
                                if feats_in is not None:
                                    pred = model(wild_ids, mut_ids, pos, feats_in).detach()
                                else:
                                    pred = model(wild_ids, mut_ids, pos).detach()
                            x_vec = pred.view(-1, 1).cpu().numpy()
                        except Exception:
                            pass
                    if x_vec is None:

                        val = np.asarray(y if ddg is not None else lab, dtype=float).reshape(-1, 1)
                        x_vec = val
                    x = x_vec

                feats_list.append(x)
                labs_list.append(lab[: x.shape[0]])  # å¯¹é½é•¿åº¦

        features = np.concatenate(feats_list, axis=0) if feats_list else None
        labels = np.concatenate(labs_list, axis=0) if labs_list else None

        if model is not None and device is not None:
            if 'model_was_train' in locals() and model_was_train:
                model.train()

    # --------- ç»Ÿä¸€åˆ° numpy ---------
    if features is None or labels is None or len(features) == 0:
        print("âš ï¸ æ²¡æœ‰å¯ç”¨äºåµŒå…¥å¯è§†åŒ–çš„æ•°æ®ï¼Œè·³è¿‡ç”Ÿæˆå›¾ã€‚")
        return

    if isinstance(features, torch.Tensor):
        features = features.detach().cpu().numpy()
    if isinstance(labels, torch.Tensor):
        labels = labels.detach().cpu().numpy()

    features = np.asarray(features)
    labels = np.asarray(labels).reshape(-1)
    N = features.shape[0]
    if labels.shape[0] != N:
        labels = labels[:N]

    if features.ndim == 1:
        features = features.reshape(-1, 1)
    if features.shape[1] < 2:
        features = np.hstack([features, np.zeros((features.shape[0], 2 - features.shape[1]))])

    # --------- PCA é™ç»´ ---------
    reducer = PCA(n_components=2)
    reduced = reducer.fit_transform(features)

    os.makedirs(save_dir, exist_ok=True)
    save_base = os.path.join(save_dir, os.path.splitext(filename)[0])

    # ç”»å›¾
    fig, ax = plt.subplots(figsize=(5.6, 4.8))
    n_classes = len(np.unique(labels))
    show_legend = n_classes <= 20

    sns.scatterplot(
        x=reduced[:, 0], y=reduced[:, 1],
        hue=labels, palette="viridis", alpha=0.75, s=40, linewidth=0, ax=ax,
        legend=show_legend
    )
    ax.set_xlabel("PC1"); ax.set_ylabel("PC2")
    ax.set_title(f"{method.upper()} of Sample Representations")
    ax.grid(True, linestyle="--", linewidth=0.6)
    if show_legend:
        ax.legend(title="Label", bbox_to_anchor=(1.02, 1), loc="upper left", borderaxespad=0., frameon=False)
    else:
        ax.legend([], [], frameon=False)

    _save(fig, save_base)
    plt.close(fig)
    print(f"âœ… ä¿å­˜åµŒå…¥å¯è§†åŒ–è‡³ï¼š{save_base}.png / .pdf")


# ============== å…¶ä»–åŠŸèƒ½å‡½æ•° ==============
def visualize_training_only(history, val_results, output_dir, config=None):
    """ç»Ÿä¸€é£æ ¼åçš„è®­ç»ƒå¯è§†åŒ–"""
    _ensure_dir(output_dir)
    
    # ä½¿ç”¨ç»Ÿä¸€çš„è®­ç»ƒæ›²çº¿å¯è§†åŒ–
    visualize_training_curves(history, output_dir)
    
    # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    report = f"""Model Performance Report
========================
Generated on: {timestamp}

[Basic Metrics]
- RMSE: {val_results['rmse']:.3f}
- MAE: {val_results.get('mae', 'NA'):.3f}
- RÂ²: {val_results.get('r2', 'NA'):.3f}
- Pearson: {val_results.get('pearson', 'NA'):.3f}

[Training Info]
- Total Epochs: {len(history['train_loss'])}
- Best Validation Epoch: {np.argmin(history['val_rmse']) + 1 if 'val_rmse' in history else 'NA'}
"""

    if config is not None:
        report += "\n[Model Hyperparameters]\n"
        for k, v in vars(config).items():
            if k.startswith('__') or callable(v):
                continue
            report += f"- {k}: {v}\n"

    with open(os.path.join(output_dir, 'performance_report.txt'), 'w') as f:
        f.write(report)

    print(f"ğŸ“Š è®­ç»ƒé˜¶æ®µå¯è§†åŒ–ç»“æœå›¾å’Œç»¼åˆæŠ¥å‘Šå·²ç”Ÿæˆå¹¶ä¿å­˜åˆ°ç›®å½•: {output_dir}")


def visualize_train_or_test_results(val_results, output_dir):
    """ç»Ÿä¸€é£æ ¼åçš„éªŒè¯/æµ‹è¯•ç»“æœå¯è§†åŒ–"""
    _ensure_dir(output_dir)
    
    if 'preds' in val_results and 'targets' in val_results:
        # ä½¿ç”¨ç»Ÿä¸€çš„é¢„æµ‹å¯è§†åŒ–
        visualize_prediction_scatter(val_results['preds'], val_results['targets'], output_dir)
        
        print(f"âœ… éªŒè¯oræµ‹è¯•é˜¶æ®µåˆ†æå›¾å·²ç”Ÿæˆå¹¶ä¿å­˜åˆ°ç›®å½•: {output_dir}")






